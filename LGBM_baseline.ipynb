{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2110,
     "status": "ok",
     "timestamp": 1584970967884,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "O20tnHOUnWGO",
    "outputId": "5511cb99-ec7d-4c21-ab87-a0b3b3e96787"
   },
   "outputs": [],
   "source": [
    "###-- Mount to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!ls 'drive/My Drive/jupyter/ProbSpace/RealEstatePrices/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkZPpZAAnWGb"
   },
   "outputs": [],
   "source": [
    "###----------------------------------------###\n",
    "###           Input information            ###\n",
    "###----------------------------------------###\n",
    "##-- CSV filename\n",
    "train_filename, test_filename = \"train_data.csv\", \"test_data.csv\"\n",
    "\n",
    "##-- Data PATH\n",
    "PATH_data = \"drive/My Drive/jupyter/ProbSpace/RealEstatePrices/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSngR_OfnWGe"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###        Import Library             ###\n",
    "###-----------------------------------###\n",
    "##-- Pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "pd.set_option('max_columns', 30)\n",
    "##-- Numpy\n",
    "import numpy as np\n",
    "##-- Matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm #-- for gradation\n",
    "import seaborn as sns\n",
    "##-- Scikit-learn\n",
    "import sklearn  #-- print(sklearn.__version__)\n",
    "\n",
    "##-- Ignore Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('bmh')\n",
    "from itertools import cycle\n",
    "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIW_GdoknWGi"
   },
   "outputs": [],
   "source": [
    "###-----------------------------###\n",
    "###        Read dataset         ###\n",
    "###-----------------------------###\n",
    "f = pd.read_csv(PATH_data+\"/\"+train_filename, encoding=\"utf-8\")\n",
    "g = pd.read_csv(PATH_data+\"/\"+test_filename, encoding=\"utf-8\")\n",
    "##-- Convert Feature names from Japanese into English\n",
    "##-- List is in \"names.json\"\n",
    "import json\n",
    "with open(PATH_data+\"/\"+\"names.json\", \"r\", encoding=\"utf-8\") as f_json:\n",
    "     d = json.load(f_json)\n",
    "f = f.rename(columns=d)\n",
    "g = g.rename(columns=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTqQ9105nWGm"
   },
   "outputs": [],
   "source": [
    "##-- Remove the values, deviating significantly\n",
    "# f = f[f[\"y\"] < (90)]\n",
    "# print(f.shape)\n",
    "# plt.hist(f['y'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNQxQTaLnWGp"
   },
   "outputs": [],
   "source": [
    "##-- Assign appropriate numerical values to non-numeric data\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('30分?60分','45')\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('1H?1H30','75')\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('1H30?2H','105')\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('2H?','120')\n",
    "f['TimeToNearestStation'] = pd.to_numeric(f['TimeToNearestStation'], errors='coerce')\n",
    "##-----------------------------------------------------------------------------\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('30分?60分','45')\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('1H?1H30','75')\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('1H30?2H','105')\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('2H?','120')\n",
    "g['TimeToNearestStation'] = pd.to_numeric(g['TimeToNearestStation'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQTu72XYnWGu"
   },
   "outputs": [],
   "source": [
    "##-- Convert the Japanese calendar to the Western calendar. \n",
    "##-- However, it is roughly the value before the war.\n",
    "f['BuildingYear'] = f['BuildingYear'].dropna()\n",
    "f['BuildingYear'] = f['BuildingYear'].str.replace('戦前','昭和20年')\n",
    "f['年号'] = f['BuildingYear'].str[:2]\n",
    "f['和暦年数'] = f['BuildingYear'].str[2:].str.strip('年').fillna(0).astype(int)\n",
    "#-- AD: Western calendar\n",
    "f.loc[f['年号']=='昭和','BuildingYear_AD'] = f['和暦年数'] + 1925\n",
    "f.loc[f['年号']=='平成','BuildingYear_AD'] = f['和暦年数'] + 1988\n",
    "##-----------------------------------------------------------------------------\n",
    "g['BuildingYear'] = g['BuildingYear'].dropna()\n",
    "g['BuildingYear'] = g['BuildingYear'].str.replace('戦前','昭和20年')\n",
    "g['年号'] = g['BuildingYear'].str[:2]\n",
    "g['和暦年数'] = g['BuildingYear'].str[2:].str.strip('年').fillna(0).astype(int)\n",
    "\n",
    "g.loc[g['年号']=='昭和','BuildingYear_AD'] = g['和暦年数'] + 1925\n",
    "g.loc[g['年号']=='平成','BuildingYear_AD'] = g['和暦年数'] + 1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLUVQ7wDnWGx"
   },
   "outputs": [],
   "source": [
    "##-- Convert \"String\" into numerical values.\n",
    "f['Area'] = f['Area'].replace('2000㎡以上',\"3500\")\n",
    "f['Area'] = f['Area'].replace('5000㎡以上',\"5000\")\n",
    "f['Area'] = pd.to_numeric(f['Area'], errors='coerce')\n",
    "\n",
    "g['Area'] = g['Area'].replace('2000㎡以上',\"3500\")\n",
    "g['Area'] = g['Area'].replace('5000㎡以上',\"5000\")\n",
    "g['Area'] = pd.to_numeric(g['Area'], errors='coerce')\n",
    "\n",
    "##-- Convert \"String\" into numerical values.\n",
    "f['TotalFloorArea'] = f['TotalFloorArea'].replace('2000㎡以上',\"3500\")\n",
    "f['TotalFloorArea'] = f['TotalFloorArea'].replace('5000㎡以上',\"5000\")\n",
    "f['TotalFloorArea'] = pd.to_numeric(f['TotalFloorArea'], errors='coerce')\n",
    "\n",
    "g['TotalFloorArea'] = g['TotalFloorArea'].replace('2000㎡以上',\"3500\")\n",
    "g['TotalFloorArea'] = g['TotalFloorArea'].replace('5000㎡以上',\"5000\")\n",
    "g['TotalFloorArea'] = pd.to_numeric(g['TotalFloorArea'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpqbaVr9nWG1"
   },
   "outputs": [],
   "source": [
    "###-- Create the enginearing feature(Number of room)\n",
    "room_code = {\\\n",
    "            \"オープンフロア\":1,\"スタジオ\":1,\"メゾネット\":2,\\\n",
    "            \"１Ｒ\":1,\"１Ｒ＋Ｓ\":1, \"１Ｋ\":1,\"１Ｋ＋Ｓ\":1,\"１ＤＫ\":2, \"１ＤＫ＋Ｓ\":2,\\\n",
    "            \"１Ｌ\":2,\"１ＬＫ\":2,\"１ＬＤＫ\":2,\"１ＬＤＫ＋Ｓ\":2,\"１ＬＫ＋Ｓ\":2,\"１Ｌ＋Ｓ\":2,\\\n",
    "            \"１ＬＤ＋Ｓ\":2,\n",
    "            \"２Ｋ\":2,\"２Ｋ＋Ｓ\":2,\"２ＤＫ\":3,\"２ＤＫ＋Ｓ\":3,\"２Ｋ＋Ｓ\":3,\"２ＬＫ＋Ｓ\":3,\\\n",
    "            \"２ＬＤ\":3,\"２Ｄ\":3,\"２ＬＤ＋Ｓ\":3,\"２ＬＫ\":3,\"２ＬＤＫ\":3,\"２ＬＤＫ＋Ｓ\":3,\\\n",
    "            \"３Ｋ\":3,\"３Ｋ＋Ｓ\":3,\"３ＤＫ\":4,\"３ＤＫ＋Ｓ\":4,\"３Ｋ＋Ｓ\":4,\"３ＬＫ＋Ｓ\":4,\\\n",
    "            \"３ＬＤ\":4,\"３ＬＤ＋Ｓ\":4,\"３ＬＫ\":4,\"３ＬＤＫ\":4,\"３ＬＤＫ＋Ｓ\":4,\"３ＬＤＫ＋Ｋ\":4,\\\n",
    "            \"４Ｋ\":4,\"４Ｋ＋Ｓ\":4,\"４ＤＫ\":5,\"４ＤＫ＋Ｓ\":5,\"４ＬＫ＋Ｓ\":5,\\\n",
    "            \"４ＬＤ\":5,\"４ＬＤ＋Ｓ\":5,\"４ＬＫ\":5,\"４ＬＤＫ\":5,\"４ＬＤＫ＋Ｓ\":5,\\\n",
    "            \"５Ｋ\":5,\"５Ｋ＋Ｓ\":5,\"５ＤＫ\":6,\"５ＤＫ＋Ｓ\":6,\"５ＬＫ＋Ｓ\":6,\"５ＬＫ＋Ｓ\":6,\\\n",
    "            \"５ＬＤ\":6,\"５ＬＤ＋Ｓ\":6,\"５ＬＫ\":6,\"５ＬＤＫ\":6,\"５ＬＤＫ＋Ｓ\":6,\\\n",
    "            \"６Ｋ\":6,\"６Ｋ＋Ｓ\":6,\"６ＤＫ\":7,\"６ＤＫ＋Ｓ\":7,\\\n",
    "            \"６ＬＤ\":7,\"６ＬＤ＋Ｓ\":7,\"６ＬＫ\":7,\"６ＬＤＫ\":7,\"６ＬＤＫ＋Ｓ\":7,\\\n",
    "            \"７Ｋ\":7,\"７Ｋ＋Ｓ\":7,\"７ＤＫ\":8,\"７ＤＫ＋Ｓ\":8,\\\n",
    "            \"７ＬＤ\":8,\"７ＬＤ＋Ｓ\":8,\"７ＬＫ\":8,\"７ＬＤＫ\":8,\"７ＬＤＫ＋Ｓ\":8,\\\n",
    "            }\n",
    "\n",
    "f[\"NumberOfRoom\"] = f[\"FloorPlan\"].copy()\n",
    "f[\"NumberOfRoom\"] = f[\"NumberOfRoom\"].fillna(1)\n",
    "g[\"NumberOfRoom\"] = g[\"FloorPlan\"].copy()\n",
    "g[\"NumberOfRoom\"] = g[\"NumberOfRoom\"].fillna(1)\n",
    "\n",
    "for name in room_code:\n",
    "    f[\"NumberOfRoom\"] = f[\"NumberOfRoom\"].replace(name, room_code[name])\n",
    "    g[\"NumberOfRoom\"] = g[\"NumberOfRoom\"].replace(name, room_code[name])\n",
    "\n",
    "# print(f[\"NumberOfRoom\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1584971320229,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "cfVLLlhOnWG4",
    "outputId": "24c5a466-8fff-459b-9b8e-e59744f4cf9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "f[\"NumberOfRoom\"].astype(int)\n",
    "g[\"NumberOfRoom\"].astype(int)\n",
    "print(f[\"NumberOfRoom\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tv7pLd1dnWG8"
   },
   "outputs": [],
   "source": [
    "###-- Create the enginearing feature(Area per a room)\n",
    "f[\"AreaPerRoom\"] = f['TotalFloorArea'] / f[\"NumberOfRoom\"]\n",
    "g[\"AreaPerRoom\"] = g['TotalFloorArea'] / g[\"NumberOfRoom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fi8Xq_ownWHC"
   },
   "outputs": [],
   "source": [
    "##-- Feature to use\n",
    "input_name = [\\\n",
    "              #-- \"延床面積（㎡）\"\n",
    "              \"TotalFloorArea\",\\\n",
    "              #-- \"面積（㎡）\"(IMPORTANT)\n",
    "              'Area',\\\n",
    "              #-- \"容積率（％）\"\n",
    "              'FloorAreaRatio',\\\n",
    "              #-- \"最寄駅：距離（分）\"\n",
    "              'TimeToNearestStation',\\\n",
    "              #-- \"建築年(西暦))\"\n",
    "              'BuildingYear_AD',\\\n",
    "              #-- \"市区町村名\"\n",
    "              'Municipality',\\\n",
    "              #-- \"最寄駅：名称\"\n",
    "              'NearestStation',\\\n",
    "              ###---  Base Line ---###\n",
    "              #-- '地区名'\n",
    "              \"DistrictName\",\\\n",
    "              ##-- \"用途\"\n",
    "              'Use',\\\n",
    "              #-- \"種類\"(IMPORTANT)\n",
    "              \"Type\",\\\n",
    "              # #-- \"今後の利用目的\"\n",
    "              # \"Purpose\",\\\n",
    "              # #-- '間取り'(IMPORTANT)\n",
    "              # 'FloorPlan',\\\n",
    "              # #-- \"改装\"\n",
    "              # \"Renovation\",\\\n",
    "              ###--- Features created by S. Nakamura ---###\n",
    "              # ##-- \"部屋の数\"\n",
    "              # \"NumberOfRoom\",\\\n",
    "              ##-- \"１部屋あたりの面積\"\n",
    "              \"AreaPerRoom\",\\\n",
    "              ]\n",
    "\n",
    "##-- Numerical variables\n",
    "nume_cols = [\\\n",
    "             \"TotalFloorArea\",\\\n",
    "             'Area',\\\n",
    "             'FloorAreaRatio',\\\n",
    "             'TimeToNearestStation',\\\n",
    "             'BuildingYear_AD',\\\n",
    "            #  \"NumberOfRoom\",\\\n",
    "             \"AreaPerRoom\",\\\n",
    "             ]\n",
    "##-- Categorical variables\n",
    "cat_cols = [\\\n",
    "            \"Municipality\",\\\n",
    "            \"NearestStation\",\\\n",
    "            ##-- Base line --##\n",
    "            \"DistrictName\",\\\n",
    "            \"Use\",\\\n",
    "            \"Type\",\\\n",
    "            # \"Purpose\",\\\n",
    "            # 'FloorPlan',\\\n",
    "            # \"Renovation\"\\\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1584971329979,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "apkYvK9gnWHH",
    "outputId": "a5c06288-b7db-41a7-fb9e-17714cc223f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalFloorArea          0\n",
      "Area                    0\n",
      "FloorAreaRatio          0\n",
      "TimeToNearestStation    0\n",
      "BuildingYear_AD         0\n",
      "Municipality            0\n",
      "NearestStation          0\n",
      "DistrictName            0\n",
      "Use                     0\n",
      "Type                    0\n",
      "AreaPerRoom             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##-- Preapare exploratory and target variables\n",
    "X = f[input_name]\n",
    "Y = f['y']\n",
    "# Y = np.log( f['y'] )  #-- 分布を正規分布に近づけるため対数をとる\n",
    "\n",
    "X_pre = g[input_name]\n",
    "\n",
    "###--------------------------------------###\n",
    "###-- Preprocessing for missing values --###\n",
    "###--------------------------------------###\n",
    "##-- In the case of \"Categorical variable\"\n",
    "for name in cat_cols:\n",
    "  X[name] = X[name].fillna(\"Unknown\")\n",
    "  X_pre[name] = X_pre[name].fillna(\"Unknown\")\n",
    "\n",
    "##-- In the case of \"Numerical variable\"\n",
    "for name in nume_cols:\n",
    "  X[name] = X[name].fillna(X[name].median())\n",
    "  X_pre[name] = X_pre[name].fillna(X_pre[name].median())\n",
    "\n",
    "\n",
    "print(X.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0cUIs4nnWHK"
   },
   "outputs": [],
   "source": [
    "# ##-- Create interacted variables\n",
    "# k = 0\n",
    "# for i in range(len(nume_cols)):\n",
    "#     for j in range(len(nume_cols)):\n",
    "#         if i == j:\n",
    "#             pass\n",
    "#         else:\n",
    "#             k += 1\n",
    "#             ##-- 積\n",
    "#             name_seki = \"feature_seki\" + str(k)\n",
    "#             X[name_seki] = X[nume_cols[i]]*X[nume_cols[j]]\n",
    "#             X_pre[name_seki] = X_pre[nume_cols[i]]*X_pre[nume_cols[j]]\n",
    "#             # ##-- 商\n",
    "#             # name_shou = \"feature_shou\" + str(k)\n",
    "#             # X[name_shou] = X[nume_cols[i]]*X[nume_cols[j]]\n",
    "#             # X_pre[name_shou] = X_pre[nume_cols[i]]*X_pre[nume_cols[j]]\n",
    "#             # ##-- 差\n",
    "#             # name_sa = \"feature_sa\" + str(k)\n",
    "#             # X[name_sa] = X[nume_cols[i]]*X[nume_cols[j]]\n",
    "#             # X_pre[name_sa] = X_pre[nume_cols[i]]*X_pre[nume_cols[j]]\n",
    "# # X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHJJ-ijInWHN"
   },
   "outputs": [],
   "source": [
    "##-- Label Encoding for categorical variable\n",
    "from sklearn import preprocessing\n",
    "\n",
    "for name in cat_cols:\n",
    "  ##-- Create the Label encoding object\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ##-- Merge the train and test datasets\n",
    "  X_fit = X[name].append(X_pre[name])\n",
    "  le.fit(X_fit)\n",
    "\n",
    "  X[name] = le.transform(X[name])\n",
    "  X_pre[name] = le.transform(X_pre[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jV1bx4TnWHQ"
   },
   "outputs": [],
   "source": [
    "###-- Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 145106,
     "status": "ok",
     "timestamp": 1584971498318,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "xcwL3F95nWHg",
    "outputId": "6b5cd711-9857-45e9-ced3-a267a74899ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 231.887\n",
      "[200]\ttrain's rmse: 227.361\n",
      "[300]\ttrain's rmse: 222.486\n",
      "[400]\ttrain's rmse: 219.73\n",
      "[500]\ttrain's rmse: 218.876\n",
      "[600]\ttrain's rmse: 217.469\n",
      "[700]\ttrain's rmse: 217.414\n",
      "Early stopping, best iteration is:\n",
      "[655]\ttrain's rmse: 216.432\n",
      "216.43240674775234\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 189.628\n",
      "[200]\ttrain's rmse: 192.374\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttrain's rmse: 188.875\n",
      "188.8747675436238\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 140.067\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttrain's rmse: 138.688\n",
      "138.6878759792056\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 173.711\n",
      "[200]\ttrain's rmse: 174.198\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttrain's rmse: 172.921\n",
      "172.9206690580867\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 255.506\n",
      "[200]\ttrain's rmse: 251.341\n",
      "[300]\ttrain's rmse: 249.004\n",
      "[400]\ttrain's rmse: 247.649\n",
      "[500]\ttrain's rmse: 245.955\n",
      "[600]\ttrain's rmse: 245.352\n",
      "[700]\ttrain's rmse: 245.022\n",
      "[800]\ttrain's rmse: 243.873\n",
      "[900]\ttrain's rmse: 242.743\n",
      "[1000]\ttrain's rmse: 243.048\n",
      "Early stopping, best iteration is:\n",
      "[901]\ttrain's rmse: 242.678\n",
      "242.67814783329857\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 280.647\n",
      "[200]\ttrain's rmse: 281.216\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttrain's rmse: 279.817\n",
      "279.8166785964779\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 171.102\n",
      "[200]\ttrain's rmse: 169.772\n",
      "[300]\ttrain's rmse: 168.821\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttrain's rmse: 167.981\n",
      "167.98106590812034\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's rmse: 348.437\n",
      "[200]\ttrain's rmse: 344.735\n",
      "[300]\ttrain's rmse: 345.197\n",
      "Early stopping, best iteration is:\n",
      "[229]\ttrain's rmse: 344.27\n",
      "344.2696657512928\n"
     ]
    }
   ],
   "source": [
    "###-- Import LightGBM --###\n",
    "import lightgbm as lgb\n",
    "\n",
    "###--  Set params  --###\n",
    "params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'learning_rate': 0.05,\n",
    "          'max_depth': 8,\n",
    "          'lambda_l1': 1.0,\n",
    "          'lambda_l2': 1.0,\n",
    "          'num_threads': 4,\n",
    "          'verbose': -1,\n",
    "          'num_leaves': 200,\n",
    "          'feature_fraction': 0.85,\n",
    "          'bagging_fraction': 0.85,\n",
    "          'bagging_freq': 5,\n",
    "          'min_child_samples': 80,\n",
    "          #-- Added\n",
    "          'seed': 99,                                                                        \n",
    "}\n",
    "\n",
    "###-- KFold Cross validation --###\n",
    "num_splits=8\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=20200102)\n",
    "\n",
    "models, loss_list = [], []\n",
    "i = 0\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "  i = i + 1\n",
    "  ###-- Set the dataset --###\n",
    "  X_kfold_train, Y_kfold_train = X_train.iloc[train_idx, :], Y_train.iloc[train_idx]\n",
    "  X_kfold_val, Y_kfold_val = X_train.iloc[val_idx, :], Y_train.iloc[val_idx]\n",
    "\n",
    "  ###-- Set dataset --###\n",
    "  train_data_set = lgb.Dataset(X_kfold_train, Y_kfold_train, categorical_feature=cat_cols)\n",
    "  test_data_set = lgb.Dataset(X_kfold_val, Y_kfold_val, reference=train_data_set)\n",
    "\n",
    "  ###--  Training  --###\n",
    "  gbm = lgb.train(\\\n",
    "                    params,\n",
    "                    train_data_set,\n",
    "                    valid_names=['train', 'valid'],\n",
    "                    valid_sets=test_data_set,\n",
    "                    # early_stopping_rounds=20,  ##--default: 20\n",
    "                    # verbose_eval=40,\n",
    "                    # num_boost_round=100,\n",
    "                    early_stopping_rounds=100,  ##--default: 20\n",
    "                    verbose_eval=100,\n",
    "                    num_boost_round=5000,\n",
    "                  )\n",
    "  \n",
    "  Y_val_pre = gbm.predict(X_kfold_val)\n",
    "\n",
    "  ##-- loss: RMSE\n",
    "  # loss = np.sqrt( sklearn.metrics.mean_squared_error(np.exp(Y_val_pre), np.exp(Y_kfold_val)) )\n",
    "  loss = np.sqrt( sklearn.metrics.mean_squared_error(Y_val_pre, Y_kfold_val) )\n",
    "  loss_list.append(loss)\n",
    "  print(loss)\n",
    "\n",
    "  #-- Keep the trained model\n",
    "  models.append(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVyKPtpgnWHl"
   },
   "outputs": [],
   "source": [
    "def predict_ensemble(models, num_model, X_pre):\n",
    "    Y_pre_list = []\n",
    "    for i in range(num_model):\n",
    "        Y_pre = models[i].predict(X_pre)\n",
    "        Y_pre_list.append(Y_pre)\n",
    "\n",
    "    Y_pre_list = np.array(Y_pre_list)\n",
    "\n",
    "    Y_pre_submit_tem = Y_pre_list[0]\n",
    "    for i in range(1, num_splits):\n",
    "        Y_pre_submit_tem += Y_pre_list[i]\n",
    "\n",
    "    Y_pre_submit = Y_pre_submit_tem / float(num_model)\n",
    "\n",
    "    return Y_pre_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7582,
     "status": "ok",
     "timestamp": 1584971824661,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "fjK34HPcnWHq",
    "outputId": "0d54ff72-9a05-47ae-c2c9-c08b546c7f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-average loss: 218.95765967723224\n",
      "validation loss: 150.42030889127952\n"
     ]
    }
   ],
   "source": [
    "print(\"train-average loss:\", np.array(loss_list).sum() / num_splits)\n",
    "\n",
    "Y_val_pre = predict_ensemble(models, num_splits, X_val)\n",
    "los_val = np.sqrt( sklearn.metrics.mean_squared_error(Y_val_pre, Y_val) )\n",
    "# los_val = np.sqrt( sklearn.metrics.mean_squared_error(np.exp(Y_val_pre), np.exp(Y_val)) )\n",
    "print(\"validation loss:\", los_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1584971836488,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "DYWneR45nWHw",
    "outputId": "70adab3e-cb03-4302-9c68-eaa1ad539776"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Area</td>\n",
       "      <td>5.725454e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalFloorArea</td>\n",
       "      <td>4.436315e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FloorAreaRatio</td>\n",
       "      <td>2.010208e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Municipality</td>\n",
       "      <td>1.979329e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TimeToNearestStation</td>\n",
       "      <td>7.897211e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AreaPerRoom</td>\n",
       "      <td>5.229591e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BuildingYear_AD</td>\n",
       "      <td>4.504509e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DistrictName</td>\n",
       "      <td>3.925658e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NearestStation</td>\n",
       "      <td>3.442482e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Use</td>\n",
       "      <td>2.653830e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Type</td>\n",
       "      <td>4.790216e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature    importance\n",
       "1                   Area  5.725454e+10\n",
       "0         TotalFloorArea  4.436315e+10\n",
       "2         FloorAreaRatio  2.010208e+10\n",
       "5           Municipality  1.979329e+10\n",
       "3   TimeToNearestStation  7.897211e+09\n",
       "10           AreaPerRoom  5.229591e+09\n",
       "4        BuildingYear_AD  4.504509e+09\n",
       "7           DistrictName  3.925658e+09\n",
       "6         NearestStation  3.442482e+09\n",
       "8                    Use  2.653830e+09\n",
       "9                   Type  4.790216e+08"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Feature': X_train.columns,\\\n",
    "              'importance':gbm.feature_importance(importance_type='gain')})\\\n",
    "              .sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTHBFbganWH1"
   },
   "outputs": [],
   "source": [
    "Y_pre_submit = predict_ensemble(models, num_splits, X_pre)\n",
    "\n",
    "# Y_pre_submit = np.exp( Y_pre_submit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9zeNRwHnWH5"
   },
   "outputs": [],
   "source": [
    "###------------------------------------###\n",
    "###        結果ファイルへの書き出し        ###\n",
    "###------------------------------------###\n",
    "from pathlib import Path\n",
    "root = Path(PATH_data)\n",
    "\n",
    "submit = pd.DataFrame({'y': Y_pre_submit})\n",
    "submit.index.name = 'id'\n",
    "submit.index = submit.index + 1\n",
    "submit.to_csv(root.joinpath(\"submission.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90y8L8hwOuxW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8w7ChVUMOuxh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LightGBM_base3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
