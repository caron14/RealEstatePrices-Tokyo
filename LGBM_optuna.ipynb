{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2754,
     "status": "ok",
     "timestamp": 1583564561745,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "awh-Q-Roj1kg",
    "outputId": "d2eb4108-5ebb-4c48-caf8-babb195ef43b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "names.json  published_land_price.csv  test_data.csv  train_data.csv\n"
     ]
    }
   ],
   "source": [
    "###-- Mount to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!ls 'drive/My Drive/jupyter/ProbSpace/RealEstatePrices/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5284,
     "status": "ok",
     "timestamp": 1583564565194,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "w8r0UfDA2vra",
    "outputId": "7cbe3046-2bb1-4c03-c1bf-ebddf1fc7b82"
   },
   "outputs": [],
   "source": [
    "#-- Install Optuna --#\n",
    "!pip install optuna\n",
    "import optuna\n",
    "print(optuna.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHBPa2O0QGrM"
   },
   "outputs": [],
   "source": [
    "###----------------------------------------###\n",
    "###           Input information            ###\n",
    "###----------------------------------------###\n",
    "##-- CSV filename\n",
    "train_filename, test_filename = \"train_data.csv\", \"test_data.csv\"\n",
    "\n",
    "##-- Data PATH\n",
    "PATH_data = \"drive/My Drive/jupyter/ProbSpace/RealEstatePrices/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXz9TzhZOuvf"
   },
   "outputs": [],
   "source": [
    "###-----------------------------------###\n",
    "###        Import Library             ###\n",
    "###-----------------------------------###\n",
    "##-- Pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "pd.set_option('max_columns', 30)\n",
    "##-- Numpy\n",
    "import numpy as np\n",
    "##-- Matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm #-- for gradation\n",
    "import seaborn as sns\n",
    "##-- Scikit-learn\n",
    "import sklearn  #-- print(sklearn.__version__)\n",
    "\n",
    "##-- Ignore Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('bmh')\n",
    "from itertools import cycle\n",
    "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejPoTxQvOuvi"
   },
   "outputs": [],
   "source": [
    "###-----------------------------###\n",
    "###        Read dataset         ###\n",
    "###-----------------------------###\n",
    "f = pd.read_csv(PATH_data+\"/\"+train_filename, encoding=\"utf-8\")\n",
    "g = pd.read_csv(PATH_data+\"/\"+test_filename, encoding=\"utf-8\")\n",
    "##-- Convert Feature names from Japanese into English\n",
    "##-- List is in \"names.json\"\n",
    "import json\n",
    "with open(PATH_data+\"/\"+\"names.json\", \"r\", encoding=\"utf-8\") as f_json:\n",
    "     d = json.load(f_json)\n",
    "f = f.rename(columns=d)\n",
    "g = g.rename(columns=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd2acXalmpCA"
   },
   "outputs": [],
   "source": [
    "##-- Assign appropriate numerical values to non-numeric data\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('30分?60分','45')\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('1H?1H30','75')\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('1H30?2H','105')\n",
    "f['TimeToNearestStation'] = f['TimeToNearestStation'].replace('2H?','120')\n",
    "f['TimeToNearestStation'] = pd.to_numeric(f['TimeToNearestStation'], errors='coerce')\n",
    "##-----------------------------------------------------------------------------\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('30分?60分','45')\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('1H?1H30','75')\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('1H30?2H','105')\n",
    "g['TimeToNearestStation'] = g['TimeToNearestStation'].replace('2H?','120')\n",
    "g['TimeToNearestStation'] = pd.to_numeric(g['TimeToNearestStation'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbJAfAFAr9Qq"
   },
   "outputs": [],
   "source": [
    "##-- Convert the Japanese calendar to the Western calendar. \n",
    "##-- However, it is roughly the value before the war.\n",
    "f['BuildingYear'] = f['BuildingYear'].dropna()\n",
    "f['BuildingYear'] = f['BuildingYear'].str.replace('戦前','昭和20年')\n",
    "f['年号'] = f['BuildingYear'].str[:2]\n",
    "f['和暦年数'] = f['BuildingYear'].str[2:].str.strip('年').fillna(0).astype(int)\n",
    "#-- AD: Western calendar\n",
    "f.loc[f['年号']=='昭和','BuildingYear_AD'] = f['和暦年数'] + 1925\n",
    "f.loc[f['年号']=='平成','BuildingYear_AD'] = f['和暦年数'] + 1988\n",
    "##-----------------------------------------------------------------------------\n",
    "g['BuildingYear'] = g['BuildingYear'].dropna()\n",
    "g['BuildingYear'] = g['BuildingYear'].str.replace('戦前','昭和20年')\n",
    "g['年号'] = g['BuildingYear'].str[:2]\n",
    "g['和暦年数'] = g['BuildingYear'].str[2:].str.strip('年').fillna(0).astype(int)\n",
    "\n",
    "g.loc[g['年号']=='昭和','BuildingYear_AD'] = g['和暦年数'] + 1925\n",
    "g.loc[g['年号']=='平成','BuildingYear_AD'] = g['和暦年数'] + 1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bD9N5OZO12Li"
   },
   "outputs": [],
   "source": [
    "##-- Convert \"String\" into numerical values.\n",
    "f['Area'] = f['Area'].replace('2000㎡以上',\"3500\")\n",
    "f['Area'] = f['Area'].replace('5000㎡以上',\"5000\")\n",
    "f['Area'] = pd.to_numeric(f['Area'], errors='coerce')\n",
    "\n",
    "g['Area'] = g['Area'].replace('2000㎡以上',\"3500\")\n",
    "g['Area'] = g['Area'].replace('5000㎡以上',\"5000\")\n",
    "g['Area'] = pd.to_numeric(g['Area'], errors='coerce')\n",
    "\n",
    "##-- Convert \"String\" into numerical values.\n",
    "f['TotalFloorArea'] = f['TotalFloorArea'].replace('2000㎡以上',\"3500\")\n",
    "f['TotalFloorArea'] = f['TotalFloorArea'].replace('5000㎡以上',\"5000\")\n",
    "f['TotalFloorArea'] = pd.to_numeric(f['TotalFloorArea'], errors='coerce')\n",
    "\n",
    "g['TotalFloorArea'] = g['TotalFloorArea'].replace('2000㎡以上',\"3500\")\n",
    "g['TotalFloorArea'] = g['TotalFloorArea'].replace('5000㎡以上',\"5000\")\n",
    "g['TotalFloorArea'] = pd.to_numeric(g['TotalFloorArea'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAfJHK8YhzIN"
   },
   "outputs": [],
   "source": [
    "##-- 使用する説明変数\n",
    "input_name = [\\\n",
    "              #-- \"最寄駅：名称\"\n",
    "              'NearestStation',\\\n",
    "              #-- \"最寄駅：距離（分）\"\n",
    "              'TimeToNearestStation',\\\n",
    "              #-- \"容積率（％）\"\n",
    "              'FloorAreaRatio',\\\n",
    "              #-- \"建築年(西暦))\"\n",
    "              'BuildingYear_AD',\\\n",
    "              ###--  Add  --###\n",
    "              #-- \"市区町村名\"\n",
    "              'Municipality',\\\n",
    "              ##-- \"面積（㎡）\"(IMPORTANT)\n",
    "              'Area',\\\n",
    "              #-- '地区名'\n",
    "              \"DistrictName\",\\\n",
    "              #-- \"今後の利用目的\"\n",
    "              \"Purpose\",\\\n",
    "              ##-- \"用途\"\n",
    "              'Use',\\\n",
    "              #-- '間取り'(IMPORTANT)\n",
    "              'FloorPlan',\\\n",
    "              #-- \"延床面積（㎡）\"\n",
    "              \"TotalFloorArea\",\\\n",
    "              #-- \"改装\"\n",
    "              \"Renovation\",\\\n",
    "              #-- \"種類\"(IMPORTANT)\n",
    "              \"Type\"\\\n",
    "              ]\n",
    "\n",
    "##-- 数値変数\n",
    "nume_cols = [\\\n",
    "             'TimeToNearestStation',\\\n",
    "             'FloorAreaRatio',\\\n",
    "             'BuildingYear_AD',\\\n",
    "             'Area',\\\n",
    "             \"TotalFloorArea\"\\\n",
    "             ]\n",
    "##-- カテゴリカル変数\n",
    "cat_cols = [\\\n",
    "            \"NearestStation\",\\\n",
    "            'Municipality',\\\n",
    "            \"DistrictName\",\\\n",
    "            \"Purpose\",\\\n",
    "            'Use',\\\n",
    "            'FloorPlan',\\\n",
    "            \"Renovation\",\\\n",
    "            \"Type\"\\\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1583564585629,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "",
      "userId": "08074476773781801102"
     },
     "user_tz": -540
    },
    "id": "ZChSI7DLsBLY",
    "outputId": "99414515-8f32-4ff3-934b-322979ff1440"
   },
   "outputs": [],
   "source": [
    "##-- Preapare exploratory and target variables\n",
    "X = f[input_name]\n",
    "Y = f['y']\n",
    "# Y = np.log( f['y'] )  #-- 分布を正規分布に近づけるため対数をとる\n",
    "\n",
    "X_pre = g[input_name]\n",
    "\n",
    "###--------------------------------------###\n",
    "###-- Preprocessing for missing values --###\n",
    "###--------------------------------------###\n",
    "##-- In the case of \"Categorical variable\"\n",
    "for name in cat_cols:\n",
    "  X[name] = X[name].fillna(\"Unknown\")\n",
    "  X_pre[name] = X_pre[name].fillna(\"Unknown\")\n",
    "\n",
    "##-- In the case of \"Numerical variable\"\n",
    "for name in nume_cols:\n",
    "  X[name] = X[name].fillna(X[name].median())\n",
    "  X_pre[name] = X_pre[name].fillna(X_pre[name].median())\n",
    "\n",
    "\n",
    "print(X.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOUA6vQNmrCa"
   },
   "outputs": [],
   "source": [
    "##-- Label Encoding for categorical variable\n",
    "from sklearn import preprocessing\n",
    "\n",
    "for name in cat_cols:\n",
    "  ##-- Create the Label encoding object\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  ##-- Merge the train and test datasets\n",
    "  X_fit = X[name].append(X_pre[name])\n",
    "  le.fit(X_fit)\n",
    "\n",
    "  X[name] = le.transform(X[name])\n",
    "  X_pre[name] = le.transform(X_pre[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7Tn4yUpoXRN"
   },
   "outputs": [],
   "source": [
    "###-- Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r6zgbIde0TC"
   },
   "outputs": [],
   "source": [
    "###-- Import LightGBM --###\n",
    "##-- LightGBM implemented with Optuna for LGBM\n",
    "# import optuna.integration.lightgbm as lgb  \n",
    "import lightgbm as lgb\n",
    "\n",
    "##-- Definition of Optuna model\n",
    "def objective_with_datasets(X_train, X_val, Y_train, Y_val):\n",
    "  ##-- Pure Optuna definition\n",
    "  def objective(trial):\n",
    "      train_x, test_x, train_y, test_y = train_test_split(X_train, Y_train, test_size=0.25)\n",
    "      dtrain = lgb.Dataset(train_x, label=train_y, categorical_feature=cat_cols)\n",
    "      dtest = lgb.Dataset(test_x, test_y, reference=dtrain)\n",
    " \n",
    "      param = {                                                                                               \n",
    "          'boosting_type': 'gbdt',                                                                             \n",
    "          'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'learning_rate': trial.suggest_loguniform('learning_rate', 1e-2, 0.1),\n",
    "          'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-6, 1.0),\n",
    "          'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-6, 1.0),\n",
    "          'num_leaves': trial.suggest_int('num_leaves', 30, 200),\n",
    "          'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "          'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "          'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "          'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "          #-- Added                                                                                \n",
    "          # 'learning_rate': 0.001,\n",
    "          'seed': 99,                                                                      \n",
    "      }  \n",
    " \n",
    "      gbm = lgb.train(param, dtrain, valid_sets=dtest)\n",
    "      Y_pre = gbm.predict(X_val)\n",
    "\n",
    "      ##-- Accuracy: RMSE\n",
    "      loss = np.sqrt( sklearn.metrics.mean_squared_error(np.exp(Y_pre), np.exp(Y_val)) )\n",
    "    \n",
    "      return loss\n",
    "    \n",
    "  return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OYO9TGMfZZ_"
   },
   "outputs": [],
   "source": [
    "##-- Optuna Go !!!\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize( objective_with_datasets(X_train, X_val, Y_train, Y_val), n_trials=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMYInQRACPOx"
   },
   "outputs": [],
   "source": [
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90y8L8hwOuxW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8w7ChVUMOuxh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LightGBM_optuna.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
